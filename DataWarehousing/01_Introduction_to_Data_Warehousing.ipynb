{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a8d1e9",
   "metadata": {},
   "source": [
    "# Data Warehousing - Part 1: Introduction & High-Level Architecture\n",
    "\n",
    "## 1. Course Agenda\n",
    "In this series, we will deep dive into the concepts of Data Warehousing. The roadmap for this course includes:\n",
    "\n",
    "1.  **Introduction:** Understanding the core concepts.\n",
    "2.  **OLTP vs. OLAP:** Differentiating between transactional and analytical systems.\n",
    "3.  **Data Modeling:** Measures, Attributes, Fact Tables, and Dimension Tables.\n",
    "4.  **Advanced Topics:** A look into complex warehousing scenarios.\n",
    "5.  **Demo:** A practical walkthrough of designing a warehouse schema.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14def068",
   "metadata": {},
   "source": [
    "## 2. What is Data Warehousing?\n",
    "\n",
    "A **Data Warehouse (DW)** is essentially a **central repository**.\n",
    "\n",
    "In a real-world enterprise, data is often scattered across various systems (sales apps, inventory logs, website tracking). These are known as **heterogeneous systems**. A Data Warehouse brings all this data together into a single location to facilitate analysis.\n",
    "\n",
    "### The Goal: Informed Decision Making\n",
    "The primary purpose of a Data Warehouse is not necessarily to run complex AI or Machine Learning models immediately, but to look at historical data trends to make **informed business decisions**.\n",
    "\n",
    "### Case Study: The Pen Store Logic\n",
    "Let's illustrate this with the example discussed. Imagine a retail business selling Pens with stores in **New York (NY)** and **San Francisco (SF)**.\n",
    "\n",
    "**The Observation (Data Analysis):**\n",
    "*   **New York Store:** In December, Red pens outsell Blue pens significantly.\n",
    "*   **San Francisco Store:** In December, Red pen sales drop, while other colors perform better.\n",
    "\n",
    "**The Informed Decision:**\n",
    "Based on this historical trend, the business decides to modify its inventory distribution for the next December:\n",
    "*   Move 90% of the **Red Pen** stock to New York.\n",
    "*   Keep only 10% of the **Red Pen** stock in San Francisco.\n",
    "\n",
    "### Simulating this in Python\n",
    "While Data Warehousing is architectural, we can simulate this \"Central Repository\" concept using Pandas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Simulate Heterogeneous Sources (Upstream Data)\n",
    "\n",
    "# Data from New York Point-of-Sale System\n",
    "ny_sales_data = {\n",
    "    'Date': ['2023-12-01', '2023-12-05', '2023-12-10'],\n",
    "    'Store_Location': ['NY', 'NY', 'NY'],\n",
    "    'Product': ['Red Pen', 'Red Pen', 'Blue Pen'],\n",
    "    'Units_Sold': [100, 150, 20]\n",
    "}\n",
    "\n",
    "# Data from San Francisco Point-of-Sale System\n",
    "sf_sales_data = {\n",
    "    'Date': ['2023-12-02', '2023-12-06', '2023-12-12'],\n",
    "    'Store_Location': ['SF', 'SF', 'SF'],\n",
    "    'Product': ['Red Pen', 'Blue Pen', 'Red Pen'],\n",
    "    'Units_Sold': [10, 50, 5]\n",
    "}\n",
    "\n",
    "df_ny = pd.DataFrame(ny_sales_data)\n",
    "df_sf = pd.DataFrame(sf_sales_data)\n",
    "\n",
    "print(\"--- Source System: NY ---\")\n",
    "display(df_ny)\n",
    "print(\"\\n--- Source System: SF ---\")\n",
    "display(df_sf)\n",
    "```\n",
    "\n",
    "```python\n",
    "# 2. The Data Warehouse (Central Repository)\n",
    "# We merge data from heterogeneous sources into one view\n",
    "\n",
    "df_warehouse = pd.concat([df_ny, df_sf], ignore_index=True)\n",
    "\n",
    "print(\"--- Data Warehouse (Central Repository) ---\")\n",
    "display(df_warehouse)\n",
    "\n",
    "# 3. Business Intelligence (The Analysis)\n",
    "# Aggregating data to find trends\n",
    "\n",
    "report = df_warehouse.groupby(['Store_Location', 'Product'])['Units_Sold'].sum().reset_index()\n",
    "\n",
    "print(\"\\n--- Analytical Report ---\")\n",
    "display(report)\n",
    "```\n",
    "\n",
    "*Note: In the output above, you can clearly see the trend that NY needs more Red Pens than SF, enabling the \"Informed Decision.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37f94b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. Business Intelligence (BI)\n",
    "\n",
    "**Business Intelligence** refers to the technical infrastructure and processes used to analyze, collect, and store data.\n",
    "\n",
    "*   **Role:** It acts as the bridge between raw data and business decisions.\n",
    "*   **Relation to DW:** BI heavily relies on the Data Warehouse as its source of truth to generate reports (like the one generated in the Python code above).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839e086",
   "metadata": {},
   "source": [
    "## 4. The Architecture: Upstream vs. Downstream\n",
    "\n",
    "When designing data pipelines, we use specific terminology to describe the flow of data.\n",
    "\n",
    "### Upstream (The Source)\n",
    "This is where the data originates. It is the \"top\" of the river.\n",
    "*   **Examples:** Point of Sales (POS) systems, CRM software, User application logs.\n",
    "*   **Characteristics:** These are usually transactional systems (capturing data as it happens).\n",
    "\n",
    "### Downstream (The Destination)\n",
    "This is where the data flows to.\n",
    "*   **Examples:** The Data Warehouse, Analytical Reporting Systems, Dashboards.\n",
    "*   **Characteristics:** These are analytical systems (reading data to understand history).\n",
    "\n",
    "### The Connector: ETL (Extract, Transform, Load)\n",
    "Between Upstream and Downstream lies the **ETL** process.\n",
    "\n",
    "1.  **Extract:** Pull data from NY and SF sources.\n",
    "2.  **Transform:** Clean the data (e.g., standardizing date formats, calculating totals).\n",
    "3.  **Load:** Push the clean data into the Data Warehouse.\n",
    "\n",
    "*(Note: Sometimes this is done as ELT - Extract, Load, and then Transform, depending on the technology stack).*\n",
    "\n",
    "### Visualizing the Flow\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    subgraph Upstream\n",
    "    A[Source: NY Store]\n",
    "    B[Source: SF Store]\n",
    "    end\n",
    "\n",
    "    subgraph Process\n",
    "    C((ETL Layer))\n",
    "    end\n",
    "\n",
    "    subgraph Downstream\n",
    "    D[(Data Warehouse)]\n",
    "    E[BI Reports]\n",
    "    end\n",
    "\n",
    "    A --> C\n",
    "    B --> C\n",
    "    C --> D\n",
    "    D --> E\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af53db8",
   "metadata": {},
   "source": [
    "## 5. Key Interview Question Teaser\n",
    "\n",
    "A common question often arises:\n",
    "> *\"If we have the data in the Source Systems (Transactional/OLTP), why do we need to copy it to a Data Warehouse? Why can't we just run reports directly on the Source?\"*\n",
    "\n",
    "We will answer this in the next notebook by exploring the differences between **OLTP** (Online Transaction Processing) and **OLAP** (Online Analytical Processing)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
