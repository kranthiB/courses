{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119ebe2a",
   "metadata": {},
   "source": [
    "# Data Warehousing - Part 3: OLAP & Analytical Reporting\n",
    "\n",
    "## 1. What is OLAP?\n",
    "**OLAP (Online Analytical Processing)** is a computing method that enables users to easily and selectively extract and view data from different points of view.\n",
    "\n",
    "While OLTP (discussed in the previous notebook) is designed for **capturing** data, OLAP is designed for **querying** and **analyzing** data.\n",
    "\n",
    "### Key Characteristics of OLAP:\n",
    "1.  **Historical Data:** unlike OLTP which might only keep the last 6-12 months of active data, OLAP systems store data from the \"origin\" (e.g., from 2001 to present) to enable trend analysis.\n",
    "2.  **Read-Optimized:** The access pattern is \"Write Once, Read Many.\" Data is loaded (via ETL) typically once a day/hour, but read thousands of times.\n",
    "3.  **Denormalized:** To speed up reads, we reduce the number of joins by combining tables. This increases data redundancy but drastically improves read performance.\n",
    "4.  **Columnar Storage:** Modern OLAP databases (like Amazon Redshift, Snowflake, Google BigQuery) often store data by **column** rather than by row, making aggregation queries (SUM, AVG) incredibly fast.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945aae09",
   "metadata": {},
   "source": [
    "## 2. The \"Why\": Solving the Dirty Data Problem\n",
    "\n",
    "One of the massive advantages of moving data to an OLAP system is **Data Cleaning**. In an OLTP system (like a website form), users might input data inconsistently. If we report directly on this, our numbers will be wrong.\n",
    "\n",
    "### Simulation: The \"Country\" Input Problem\n",
    "Imagine an e-commerce checkout form where the \"Country\" field is a text box.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Simulate Raw OLTP Data (User Input)\n",
    "# Notice the inconsistency in the 'Country' column.\n",
    "oltp_data = {\n",
    "    'OrderID': [1, 2, 3, 4, 5, 6],\n",
    "    'Customer': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Amount': [100, 200, 150, 300, 120, 250],\n",
    "    'Country': ['IN', 'India', 'ind', 'INDIA', 'US', 'USA']\n",
    "}\n",
    "\n",
    "df_oltp = pd.DataFrame(oltp_data)\n",
    "\n",
    "print(\"--- Raw OLTP Data ---\")\n",
    "display(df_oltp)\n",
    "\n",
    "# 2. Trying to generate a report on OLTP\n",
    "# Result: The data is fragmented. 'India' is split into 4 different categories.\n",
    "print(\"\\n--- Failed Report on Raw Data ---\")\n",
    "report_fail = df_oltp.groupby('Country')['Amount'].sum()\n",
    "display(report_fail)\n",
    "```\n",
    "\n",
    "### The OLAP Solution (ETL Process)\n",
    "Before the data enters the Data Warehouse (OLAP), it goes through an **ETL (Extract, Transform, Load)** process where these inconsistencies are mapped to a standard value.\n",
    "\n",
    "```python\n",
    "# 3. Simulate ETL Process (Transformation)\n",
    "def clean_country(country_code):\n",
    "    code = country_code.upper().strip()\n",
    "    if code in ['IN', 'IND', 'INDIA', 'HINDUSTAN']:\n",
    "        return 'India'\n",
    "    elif code in ['US', 'USA', 'UNITED STATES']:\n",
    "        return 'USA'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Apply transformation\n",
    "df_olap = df_oltp.copy()\n",
    "df_olap['Country'] = df_olap['Country'].apply(clean_country)\n",
    "\n",
    "print(\"--- Cleaned OLAP Data ---\")\n",
    "display(df_olap)\n",
    "\n",
    "# 4. Generate Analytical Report\n",
    "# Result: Accurate aggregation.\n",
    "print(\"\\n--- Successful Analytical Report ---\")\n",
    "report_success = df_olap.groupby('Country')['Amount'].sum()\n",
    "display(report_success)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d184f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. The \"Why\": Solving the Performance Problem\n",
    "\n",
    "### The Denormalization Advantage\n",
    "In the previous notebook, we saw that to get a simple invoice in OLTP, we had to join **4 tables**. In OLAP, we denormalize this into \"Wide Tables\" or \"Star Schemas\".\n",
    "\n",
    "Let's simulate a Denormalized table. Instead of 4 tables, we keep everything together.\n",
    "\n",
    "```python\n",
    "# Simulating a Denormalized OLAP Table\n",
    "# Note: Data redundancy (Alice's address is repeated), but Joins are eliminated.\n",
    "\n",
    "olap_wide_table = {\n",
    "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "    'Product_Category': ['Stationery', 'Stationery', 'Electronics', 'Stationery'],\n",
    "    'Product_Name': ['Red Pen', 'Blue Pen', 'Mouse', 'Red Pen'],\n",
    "    'Customer_Region': ['NY', 'NY', 'SF', 'NY'],\n",
    "    'Sales_Amount': [10, 10, 50, 20]\n",
    "}\n",
    "\n",
    "df_wide = pd.read_sql_query # Just using pandas for simulation\n",
    "df_wide = pd.DataFrame(olap_wide_table)\n",
    "\n",
    "print(\"--- Denormalized Wide Table (OLAP) ---\")\n",
    "display(df_wide)\n",
    "\n",
    "# Querying is now instant (No Joins required)\n",
    "# Manager asks: \"Show me Red Pen sales in NY\"\n",
    "analytics_query = df_wide[\n",
    "    (df_wide['Product_Name'] == 'Red Pen') & \n",
    "    (df_wide['Customer_Region'] == 'NY')\n",
    "]['Sales_Amount'].sum()\n",
    "\n",
    "print(f\"\\nTotal Red Pen Sales in NY: ${analytics_query}\")\n",
    "```\n",
    "\n",
    "### Row vs. Columnar Storage\n",
    "*   **Row Store (OLTP like MySQL/Postgres):** Data is stored row-by-row on the disk. Great for fetching *one specific user's* order.\n",
    "*   **Column Store (OLAP like Redshift/BigQuery):** Data is stored column-by-column.\n",
    "    *   *Scenario:* If you want the **Average Sales Amount** for 1 billion rows.\n",
    "    *   *Row Store:* Must read the entire row (Name, Date, Address, **Amount**) for 1 billion records. Heavy I/O.\n",
    "    *   *Column Store:* Only reads the **Amount** column block. Massive performance gain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403890f9",
   "metadata": {},
   "source": [
    "## 4. Summary: OLTP vs. OLAP\n",
    "\n",
    "| Feature | OLTP (Transactional) | OLAP (Analytical) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Purpose** | Run the business (Day-to-day) | Analyze the business (Trends) |\n",
    "| **Data Source** | Live User Inputs | Aggregated & Cleaned from OLTP |\n",
    "| **Data History** | Recent (e.g., 6 months) | Historic (e.g., 10 years) |\n",
    "| **Normalization** | Highly Normalized (3NF) | Denormalized (Star Schema) |\n",
    "| **Operations** | High Read/Write (CRUD) | Mostly Read (Complex Selects) |\n",
    "| **Users** | Thousands (Customers/Clerks) | Few (Analysts/Managers/CEOs) |\n",
    "| **Query Speed** | Fast for single records | Fast for aggregations (Sum/Avg) |\n",
    "\n",
    "### The Verdict\n",
    "We **cannot** run analytical queries on OLTP systems because:\n",
    "1.  **Performance:** Reading millions of rows locks the database, preventing customers from placing new orders (Read/Write contention).\n",
    "2.  **Data Quality:** OLTP data is \"dirty\" (raw input). OLAP data is \"clean\" (Source of Truth).\n",
    "3.  **Complexity:** Business users cannot write queries with 15 Joins. OLAP simplifies the structure."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
