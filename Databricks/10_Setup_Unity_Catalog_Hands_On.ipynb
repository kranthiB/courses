{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595fd2ee",
   "metadata": {},
   "source": [
    "# Setup Unity Catalog: Hands-on Guide\n",
    "\n",
    "**Objective:** Enable Unity Catalog for our Databricks workspace. This involves creating a **Metastore**, setting up cloud storage for that metastore, and assigning the metastore to our workspace.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Prerequisites Checklist\n",
    "Before we begin, ensure you have the following ready in your Azure Portal:\n",
    "1.  **Resource Group:** The one we created earlier (e.g., `self-adb-rg`).\n",
    "2.  **Databricks Workspace:** Created and running.\n",
    "3.  **Permissions:** You must be an **Account Admin** in Databricks and have **Owner/Contributor** rights on the Azure Subscription/Resource Group.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Step-by-Step Setup Guide\n",
    "\n",
    "### Step A: Create Storage Account for Metastore (Azure Portal)\n",
    "Unity Catalog needs a place to store the actual data for \"Managed Tables\".\n",
    "1.  Go to **Azure Portal** -> **Create a resource** -> **Storage account**.\n",
    "2.  **Resource Group:** `self-adb-rg`.\n",
    "3.  **Name:** Unique name (e.g., `adbself01`).\n",
    "4.  **Region:** **MUST MATCH** your Databricks Workspace region (e.g., `Central India`).\n",
    "5.  **Advanced Tab:** Enable **Hierarchical namespace** (ADLS Gen2). **This is mandatory.**\n",
    "6.  Review & Create.\n",
    "\n",
    "### Step B: Create Container\n",
    "1.  Go to the new Storage Account -> **Containers**.\n",
    "2.  Create a container named `root` (or `metastore`).\n",
    "3.  Inside `root`, create a directory named `metastore`.\n",
    "\n",
    "### Step C: Create Access Connector for Azure Databricks\n",
    "This is a specific Azure resource that allows Unity Catalog to access the storage account securely.\n",
    "1.  Search for **Access Connector for Azure Databricks**.\n",
    "2.  Click **Create**.\n",
    "3.  **Resource Group:** `self-adb-rg`.\n",
    "4.  **Name:** `adb-uc-connector`.\n",
    "5.  **Region:** Same as workspace (`Central India`).\n",
    "6.  Review & Create.\n",
    "7.  **Important:** Once created, go to the resource and copy the **Resource ID**. It looks like `/subscriptions/.../providers/Microsoft.Databricks/accessConnectors/...`.\n",
    "\n",
    "### Step D: Grant Permissions (IAM)\n",
    "The Access Connector needs permission to talk to the Storage Account.\n",
    "1.  Go to your **Storage Account** (`adbself01`).\n",
    "2.  Click **Access Control (IAM)** -> **Add role assignment**.\n",
    "3.  **Role:** `Storage Blob Data Contributor`.\n",
    "4.  **Assign access to:** `Managed Identity`.\n",
    "5.  **Select Members:** Choose the **Access Connector** created in Step C.\n",
    "6.  Review & Assign.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Configure Unity Catalog (Databricks Account Console)\n",
    "\n",
    "Now we switch to the **Databricks Account Console** (`https://accounts.azuredatabricks.net`).\n",
    "\n",
    "1.  Go to **Catalog** tab.\n",
    "2.  Click **Create Metastore**.\n",
    "3.  **Name:** `azure-central-india` (Naming convention: cloud-region).\n",
    "4.  **Region:** `Central India`.\n",
    "5.  **ADLS Gen 2 Path:**\n",
    "    *   Format: `abfss://<container>@<storage-account>.dfs.core.windows.net/<path>`\n",
    "    *   Example: `abfss://root@adbself01.dfs.core.windows.net/metastore`\n",
    "6.  **Access Connector ID:** Paste the **Resource ID** copied in Step C.\n",
    "7.  Click **Create**.\n",
    "\n",
    "### Step E: Assign to Workspace\n",
    "1.  After creating the metastore, you will be prompted to assign workspaces.\n",
    "2.  Select your workspace (`self-adb`).\n",
    "3.  Click **Assign**.\n",
    "4.  Click **Enable**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Verification\n",
    "\n",
    "1.  Go back to your **Databricks Workspace**.\n",
    "2.  Click on **Catalog** in the left sidebar.\n",
    "3.  You should now see a catalog named `main` (or the default catalog created by UC) alongside `hive_metastore`.\n",
    "4.  **Success!** Unity Catalog is now active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377d95b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Verification Code\n",
    "# Run this in your Databricks Workspace Notebook to confirm UC is enabled.\n",
    "\n",
    "try:\n",
    "    # List available catalogs. If UC is enabled, you will see more than just 'hive_metastore'\n",
    "    df = spark.sql(\"SHOW CATALOGS\")\n",
    "    display(df)\n",
    "    \n",
    "    print(\"If you see 'main' or 'system' catalogs, Unity Catalog is ENABLED.\")\n",
    "except Exception as e:\n",
    "    print(\"Error checking catalogs. Ensure cluster is running.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8110e",
   "metadata": {},
   "source": [
    "## 5. Key Takeaways\n",
    "*   **One Metastore per Region:** You generally create one metastore for a specific region and attach all workspaces in that region to it.\n",
    "*   **Managed Identity:** We used a secure Access Connector (Managed Identity) instead of access keys. This is the secure, modern way to connect Azure resources.\n",
    "*   **Root Storage:** The ADLS path we configured is the default home for all \"Managed Tables\" created in this metastore.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "Now that Unity Catalog is set up, in the next session, we will start creating **Catalogs, Schemas, and Tables** within Unity Catalog and learn about managing permissions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
