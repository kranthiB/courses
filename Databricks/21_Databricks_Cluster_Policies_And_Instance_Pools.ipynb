{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2756fc",
   "metadata": {},
   "source": [
    "# Cluster Policies & Instance Pools\n",
    "## Databricks Zero to Hero - Part 21\n",
    "\n",
    "**Objective:** Learn how to manage compute resources effectively using **Cluster Policies** to enforce governance and cost controls, and **Instance Pools** to reduce cluster start-up times.\n",
    "\n",
    "### Topics Covered:\n",
    "1.  **Cluster Policies:** Creating custom policies to restrict user access to compute configurations (e.g., enforcing auto-termination, restricting instance types).\n",
    "2.  **Enforcing Policies:** How to update policies and remediate non-compliant clusters.\n",
    "3.  **Instance Pools:** Understanding \"Warm\" vs \"Cold\" instances to speed up job execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3b049",
   "metadata": {},
   "source": [
    "## 1. Cluster Policies\n",
    "\n",
    "Cluster policies allow administrators to limit the compute creation permissions of users. This is crucial for:\n",
    "*   **Cost Control:** Prevent users from creating massive, expensive clusters.\n",
    "*   **Governance:** Enforce tags, runtime versions, or auto-termination rules.\n",
    "\n",
    "### Use Case Scenario\n",
    "We want to create a **\"Custom Shared Compute\"** policy with the following strict rules:\n",
    "1.  **Fixed Auto-Termination:** 10 minutes (Users cannot change this).\n",
    "2.  **Fixed Size:** Exactly 1 Worker (No Autoscaling).\n",
    "3.  **Fixed Runtime:** Specific Databricks Runtime (e.g., 14.3 LTS).\n",
    "4.  **Restricted Node Types:** Users can only select specific instance types (e.g., Standard_DS4_v2).\n",
    "\n",
    "### Policy JSON Structure\n",
    "Policies are defined using JSON. Below is the JSON configuration derived from the video insights to achieve the rules above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fd463",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "// Copy this JSON into the Databricks Policy Editor (Compute -> Policies -> Create/Edit)\n",
    "\n",
    "{\n",
    "  \"spark_conf.spark.databricks.cluster.profile\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": \"serverless\",\n",
    "    \"hidden\": true\n",
    "  },\n",
    "  \"autotermination_minutes\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": 10,\n",
    "    \"hidden\": false\n",
    "  },\n",
    "  \"num_workers\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": 1,\n",
    "    \"hidden\": false\n",
    "  },\n",
    "  \"autoscale.min_workers\": {\n",
    "    \"type\": \"forbidden\"\n",
    "  },\n",
    "  \"autoscale.max_workers\": {\n",
    "    \"type\": \"forbidden\"\n",
    "  },\n",
    "  \"spark_version\": {\n",
    "    \"type\": \"fixed\",\n",
    "    \"value\": \"14.3.x-scala2.12\",\n",
    "    \"hidden\": false\n",
    "  },\n",
    "  \"node_type_id\": {\n",
    "    \"type\": \"allowlist\",\n",
    "    \"values\": [\n",
    "      \"Standard_DS4_v2\",\n",
    "      \"Standard_DS3_v2\"\n",
    "    ],\n",
    "    \"defaultValue\": \"Standard_DS4_v2\"\n",
    "  },\n",
    "  \"driver_node_type_id\": {\n",
    "    \"type\": \"allowlist\",\n",
    "    \"values\": [\n",
    "      \"Standard_DS4_v2\",\n",
    "      \"Standard_DS3_v2\"\n",
    "    ],\n",
    "    \"defaultValue\": \"Standard_DS4_v2\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09982eb6",
   "metadata": {},
   "source": [
    "### Key Policy Attributes Explained:\n",
    "*   `\"type\": \"fixed\"`: The user sees the value but cannot change it.\n",
    "*   `\"type\": \"forbidden\"`: The setting (like autoscaling) is completely hidden or disabled.\n",
    "*   `\"type\": \"allowlist\"`: Provides a specific dropdown of options the user must choose from.\n",
    "*   `\"hidden\": true`: The user doesn't even see this setting in the UI.\n",
    "\n",
    "### Policy Enforcement & Compliance\n",
    "If you edit an existing policy (e.g., upgrade the `spark_version` to 15.4 LTS), clusters currently using that policy will be flagged as **Non-Compliant**.\n",
    "*   **Action:** In the Policies UI, you can click **\"Fix\"** or **\"Fix All\"** to automatically update the existing clusters to match the new policy rules (this requires a restart of the clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafc66c",
   "metadata": {},
   "source": [
    "## 2. Instance Pools\n",
    "\n",
    "Instance Pools are a set of idle, ready-to-use instances managed by Databricks. They allow you to reduce the start-up time of clusters from minutes to seconds.\n",
    "\n",
    "### Concepts:\n",
    "1.  **Min Idle (Warm Pool):** The minimum number of instances the pool keeps running *even when no jobs are using them*.\n",
    "    *   *Benefit:* Immediate availability.\n",
    "    *   *Cost:* You pay for these instances while they are idle (DBU cost is usually waived, but Cloud Provider VM cost applies).\n",
    "2.  **Max Capacity:** The hard limit on the number of instances the pool can provision.\n",
    "3.  **Idle Instance Auto Termination:** How long an instance stays in the pool after a job releases it before it is terminated by the cloud provider.\n",
    "\n",
    "### Example Configuration (from Video)\n",
    "*   **Pool Name:** `Demo Pool`\n",
    "*   **Min Idle:** `1` (Keeps 1 node running 24/7 - enables \"Warm\" starts)\n",
    "*   **Max Capacity:** `10`\n",
    "*   **Idle Auto Termination:** `10 minutes`\n",
    "\n",
    "### How to use?\n",
    "When creating a Cluster (Compute), instead of selecting a \"Worker Type\" (like Standard_DS3_v2), you select the **Instance Pool** you created. The cluster will grab resources from that pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61243fe0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Practical Tip: Using Python/API to list Instance Pools (Optional)\n",
    "# This requires the Databricks SDK or proper authentication setup.\n",
    "\n",
    "try:\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    w = WorkspaceClient()\n",
    "\n",
    "    print(\"Listing available Instance Pools:\")\n",
    "    for pool in w.instance_pools.list():\n",
    "        print(f\"Pool Name: {pool.instance_pool_name}, ID: {pool.instance_pool_id}\")\n",
    "        print(f\"  - Min Idle: {pool.min_idle_instances}\")\n",
    "        print(f\"  - Max Capacity: {pool.max_capacity}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Databricks SDK not installed. You can manage pools via the 'Compute' -> 'Pools' tab in the UI.\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: This code block requires API configuration. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234e333",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Feature | Primary Goal | Key Action |\n",
    "| :--- | :--- | :--- |\n",
    "| **Cluster Policies** | Governance & Cost Control | Restrict settings via JSON (Fixed, Forbidden, Allowlist). |\n",
    "| **Instance Pools** | Performance (Startup Time) | Maintain \"Warm\" instances (`Min Idle`) for rapid deployment. |\n",
    "\n",
    "**Next Steps:** In the next session, we will start working with **Databricks Workflows (Jobs)** to orchestrate our pipelines."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
