{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7353c58a",
   "metadata": {},
   "source": [
    "# Databricks Workflows & Orchestration\n",
    "## Zero to Hero: Jobs, Task Values, If/Else, and For Each Loops\n",
    "\n",
    "**Objective:** Learn how to orchestrate complex data pipelines using Databricks Workflows. We will move beyond simple `dbutils.notebook.run` and use the native Jobs UI to handle dependencies, conditions, and loops.\n",
    "\n",
    "### Agenda\n",
    "1.  **Task Values:** Passing variables between different tasks in a Job.\n",
    "2.  **If/Else Condition:** branching logic based on task outputs.\n",
    "3.  **For Each Loop:** Running a task dynamically for a list of inputs.\n",
    "4.  **Repair Run:** How to re-run only failed tasks.\n",
    "\n",
    "---\n",
    "### Setup: Create 3 Helper Notebooks\n",
    "To build this workflow, we first need to create 3 separate notebooks in your workspace. Copy the code blocks below into specific files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596317c",
   "metadata": {},
   "source": [
    "### Notebook A: `01_get_run_day`\n",
    "**Purpose:** Accepts a date parameter, determines the day of the week (e.g., \"Sun\", \"Mon\"), and passes this value to the next task.\n",
    "\n",
    "**Copy this code into a new notebook named `01_get_run_day`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cafdc0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- CODE FOR NOTEBOOK: 01_get_run_day ---\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, date_format\n",
    "\n",
    "# 1. Create a widget to accept input date (Format: yyyy-MM-dd-HH-mm-ss)\n",
    "dbutils.widgets.text(\"input_date\", \"\")\n",
    "input_date_str = dbutils.widgets.get(\"input_date\")\n",
    "\n",
    "print(f\"Input Date: {input_date_str}\")\n",
    "\n",
    "# 2. Logic to determine the Day of the Week (Sun, Mon, Tue...)\n",
    "# We create a temporary dataframe to use Spark SQL functions\n",
    "df = spark.createDataFrame([{\"date_str\": input_date_str}])\n",
    "\n",
    "# Convert string to timestamp and extract Day (E pattern gives Sun, Mon etc)\n",
    "# Note: In Spark 3+, usually 'E' is used for day of week name abbreviated\n",
    "result_df = df.select(date_format(to_timestamp(\"date_str\", \"yyyy-MM-dd-HH-mm-ss\"), \"E\").alias(\"day\"))\n",
    "\n",
    "# Collect the result to a Python variable\n",
    "day_of_week = result_df.collect()[0][\"day\"]\n",
    "\n",
    "print(f\"Calculated Day: {day_of_week}\")\n",
    "\n",
    "# 3. SET TASK VALUE\n",
    "# This allows other tasks in the Workflow to read this value\n",
    "dbutils.jobs.taskValues.set(key=\"input_day\", value=day_of_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f43b8",
   "metadata": {},
   "source": [
    "### Notebook B: `02_process_data`\n",
    "**Purpose:** This will simulate the actual data processing. We will run this inside a **For Each** loop to process different departments.\n",
    "\n",
    "**Copy this code into a new notebook named `02_process_data`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc753c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- CODE FOR NOTEBOOK: 02_process_data ---\n",
    "\n",
    "# 1. Receive parameters\n",
    "dbutils.widgets.text(\"dept\", \"general\")\n",
    "department = dbutils.widgets.get(\"dept\")\n",
    "\n",
    "print(f\"Processing data for Department: {department}\")\n",
    "\n",
    "# Simulate processing logic\n",
    "import time\n",
    "time.sleep(5) # Sleeping to simulate work\n",
    "\n",
    "print(f\"Successfully processed {department} data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89109e5",
   "metadata": {},
   "source": [
    "### Notebook C: `03_else_condition`\n",
    "**Purpose:** This task runs if the condition is FALSE (i.e., if it is not Sunday). It demonstrates how to **GET** values passed from previous tasks.\n",
    "\n",
    "**Copy this code into a new notebook named `03_else_condition`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495e755",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- CODE FOR NOTEBOOK: 03_else_condition ---\n",
    "\n",
    "# 1. GET TASK VALUE from the first task\n",
    "# \"01_set_day\" is the Task Name we will define in the Workflow UI\n",
    "# \"input_day\" is the key we set in Notebook A\n",
    "prev_task_day = dbutils.jobs.taskValues.get(taskKey=\"01_set_day\", key=\"input_day\", default=\"Unknown\")\n",
    "\n",
    "print(\"Condition Not Met.\")\n",
    "print(f\"The calculated day was: {prev_task_day}. No processing required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12973850",
   "metadata": {},
   "source": [
    "## Creating the Workflow (UI Steps)\n",
    "\n",
    "Now that the code is ready, follow these steps to build the Job:\n",
    "\n",
    "### Step 1: Create the Job\n",
    "1. Go to **Workflows** -> **Create Job**.\n",
    "2. Name the Job: `Process_Emp_Data_By_Dept`.\n",
    "\n",
    "### Step 2: Add First Task (Get Day)\n",
    "1. **Task Name:** `01_set_day` (Important: Must match the `taskKey` used in Notebook C).\n",
    "2. **Type:** Notebook.\n",
    "3. **Path:** Select `01_get_run_day`.\n",
    "4. **Parameters:**\n",
    "   - Key: `input_date`\n",
    "   - Value: `{{job.start_time_iso_date}}` (Dynamic Value) or a hardcoded date like `2024-10-27-13-00-00`.\n",
    "5. Click **Create**.\n",
    "\n",
    "### Step 3: Add Logic (If/Else Condition)\n",
    "1. Click the **+** icon next to `01_set_day` to add a downstream task.\n",
    "2. Select **If/else condition**.\n",
    "3. **Task Name:** `check_day`.\n",
    "4. **Condition:**\n",
    "   - Left operand type: `Dynamic Value`\n",
    "   - Value: `{{tasks.01_set_day.values.input_day}}` (This reads the value set by `dbutils.jobs.taskValues.set`).\n",
    "   - Operator: `==` (Equals).\n",
    "   - Right operand: `Sun` (String).\n",
    "5. Click **Create**.\n",
    "\n",
    "### Step 4: Add True Path (For Each Loop)\n",
    "1. Click the **+** on the **True** branch of the condition.\n",
    "2. Select **For each**.\n",
    "3. **Task Name:** `process_data_loop`.\n",
    "4. **Inputs:** `[\"sales\", \"office\"]` (JSON Array).\n",
    "5. **Task to run:** Select Notebook.\n",
    "   - **Path:** Select `02_process_data`.\n",
    "   - **Parameters:**\n",
    "     - Key: `dept`\n",
    "     - Value: `{{input}}` (This passes the current item from the loop array).\n",
    "6. Click **Create**.\n",
    "\n",
    "### Step 5: Add False Path (Else Condition)\n",
    "1. Click the **+** on the **False** branch.\n",
    "2. **Task Name:** `03_else_logic`.\n",
    "3. **Type:** Notebook.\n",
    "4. **Path:** Select `03_else_condition`.\n",
    "5. Click **Create**.\n",
    "\n",
    "---\n",
    "\n",
    "## Running & Repairing\n",
    "\n",
    "1. **Run Now:** Click \"Run Now\".\n",
    "   - If today is Sunday (or if you passed a Sunday date), the **True** path runs.\n",
    "   - You will see the loop processing \"sales\" and \"office\" concurrently or sequentially.\n",
    "   - If not Sunday, the **False** path runs.\n",
    "\n",
    "2. **Repair Run:**\n",
    "   - If a task fails (e.g., you introduce a typo), fix the notebook code.\n",
    "   - Go to the Job Run page.\n",
    "   - Click **Repair Run**.\n",
    "   - Select the failed tasks. Databricks will *skip* the successful tasks and only run the repaired ones."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
