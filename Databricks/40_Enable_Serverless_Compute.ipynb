{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aad8724",
   "metadata": {},
   "source": [
    "# Enable Serverless Compute on Azure Databricks\n",
    "\n",
    "In this notebook, we will explore **Serverless Compute**, a paradigm shift in how Databricks resources are managed. We will cover what it is, how the architecture differs from classic compute, how to enable it, and how to use it across Notebooks, Jobs, and DLT pipelines.\n",
    "\n",
    "### Learning Objectives\n",
    "1.  Understand the concept and benefits of Serverless Compute.\n",
    "2.  Analyze the **Architecture Shift** (Classic vs. Serverless).\n",
    "3.  Check Regional Availability.\n",
    "4.  Enable Serverless Compute in the Account Console.\n",
    "5.  Set up **Budget Policies** for cost tracking.\n",
    "6.  Hands-on: Running Serverless Notebooks (Python & SQL).\n",
    "7.  Hands-on: Using Serverless in Workflows and DLT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30b6e4",
   "metadata": {},
   "source": [
    "## 1. What is Serverless Compute?\n",
    "\n",
    "Serverless compute in Databricks means you no longer have to configure, manage, or wait for clusters to start.\n",
    "\n",
    "*   **Instant Startup:** Serverless compute starts in seconds, unlike classic clusters which can take minutes.\n",
    "*   **No Administration:** No need to choose instance types, driver sizes, or auto-scaling policies. Databricks manages the fleet.\n",
    "*   **Elasticity:** It scales up and down instantly based on workload demand.\n",
    "*   **Cost Efficiency:** You are billed only for the time your code runs (plus a minimal startup time), avoiding idle cluster costs.\n",
    "\n",
    "### Supported Workloads\n",
    "As of now, Serverless is available for:\n",
    "*   Notebooks\n",
    "*   Jobs / Workflows\n",
    "*   Delta Live Tables (DLT)\n",
    "*   Databricks SQL Warehouses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e593a",
   "metadata": {},
   "source": [
    "## 2. Architecture Shift: Classic vs. Serverless\n",
    "\n",
    "There is a fundamental change in where the compute resources live.\n",
    "\n",
    "### Classic Compute Plane\n",
    "*   **Location:** Lives in **Your Cloud Account** (the Customer's Data Plane/VNet).\n",
    "*   **Management:** You manage the VNet, security groups, and quota.\n",
    "*   **Latency:** VM startup takes time (acquiring resources from Azure/AWS).\n",
    "\n",
    "### Serverless Compute Plane\n",
    "*   **Location:** Lives in a **Databricks Managed Compute Plane** (within the Databricks Account).\n",
    "*   **Connection:** It connects securely to your storage to process data.\n",
    "*   **Isolation:**\n",
    "    *   Databricks maintains a warm pool of VMs.\n",
    "    *   When you request compute, a VM is assigned exclusively to you.\n",
    "    *   **Security:** Once your task is done, the VM is scrubbed/terminated and never reused for another customer, ensuring strict data isolation.\n",
    "*   **Networking:** It is typically deployed in the same region as your workspace to minimize latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd1b06d",
   "metadata": {},
   "source": [
    "## 3. Prerequisites & Availability\n",
    "\n",
    "Serverless is not available in every region immediately. Before trying to enable it, you must verify if your workspace region supports it.\n",
    "\n",
    "1.  Go to the [Azure Databricks Regional Availability](https://learn.microsoft.com/en-us/azure/databricks/resources/feature-region-support) page.\n",
    "2.  Check the \"Serverless SQL and Serverless Compute\" column.\n",
    "3.  Ensure your workspace region (e.g., `Central India`, `East US`) is listed.\n",
    "\n",
    "*Note: If your workspace is in a region that doesn't support Serverless (e.g., South India at the time of recording), you will not see the option to enable it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c5d85",
   "metadata": {},
   "source": [
    "## 4. How to Enable Serverless\n",
    "\n",
    "If Serverless is not enabled by default in your workspace (often the case for existing Azure workspaces), an **Account Admin** must enable it.\n",
    "\n",
    "**Steps:**\n",
    "1.  Go to **Manage Account** (Account Console).\n",
    "2.  Navigate to **Settings** -> **Feature Enablement**.\n",
    "3.  Locate **Serverless compute for Notebooks, Workflows, and Delta Live Tables**.\n",
    "4.  Toggle the switch to **Enable**.\n",
    "\n",
    "*Once enabled, the feature becomes available to all eligible workspaces in the account.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4a6f8",
   "metadata": {},
   "source": [
    "## 5. Cost Management: Budget Policies\n",
    "\n",
    "Since Serverless resources are managed by Databricks, you pay a \"DBU price\" that includes both the compute and the software license. To track these costs effectively, we use **Budget Policies**.\n",
    "\n",
    "### Steps to create a Budget Policy:\n",
    "1.  Go to Workspace **Settings** -> **Compute**.\n",
    "2.  Find **Budget Policies** and click **Manage**.\n",
    "3.  Click **Create Budget Policy**.\n",
    "    *   **Name:** e.g., `Demo_Budget`\n",
    "    *   **Tags:** Add custom tags (e.g., `Key: CostCenter`, `Value: DataTeam`).\n",
    "4.  **Permissions:** By default, only the creator has permission. You must **Grant Access** to other users or groups so they can assign their Serverless workloads to this policy.\n",
    "\n",
    "*Tagging is crucial for attributing costs in your billing reports.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4faf3",
   "metadata": {},
   "source": [
    "## 6. Hands-on: Serverless with Notebooks\n",
    "\n",
    "Let's see Serverless in action.\n",
    "\n",
    "**Steps:**\n",
    "1.  Open a Notebook.\n",
    "2.  Click the **Connect** dropdown (Compute selector) at the top right.\n",
    "3.  Select **Serverless**.\n",
    "4.  Notice the status changes to \"Connected\" almost instantly.\n",
    "\n",
    "**Configuration:**\n",
    "*   You can select **Environment** (Standard vs. High Memory) via the configuration pane.\n",
    "*   **Languages:** Currently, Serverless for notebooks primarily supports **Python** and **SQL**.\n",
    "*   **Budget Policy:** You can assign the policy created in step 5 here.\n",
    "\n",
    "Let's run some code to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33088f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Run a PySpark command on Serverless\n",
    "# Note how fast the execution starts compared to waiting for a cluster driver.\n",
    "\n",
    "display(spark.range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721ff99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Check Spark Configuration context (Optional)\n",
    "# This confirms we are running in a serverless environment context.\n",
    "\n",
    "print(spark.conf.get(\"spark.databricks.service.serverless.enabled\", \"false\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33945d00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "-- 3. Run SQL on Serverless\n",
    "-- You can use the %sql magic command.\n",
    "\n",
    "SELECT * FROM range(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60fe65",
   "metadata": {},
   "source": [
    "## 7. Serverless for Jobs & DLT\n",
    "\n",
    "### Workflows (Jobs)\n",
    "You can easily swap existing jobs to run on Serverless without rewriting code.\n",
    "1.  Go to **Workflows**.\n",
    "2.  Select a Job.\n",
    "3.  In the **Compute** section (right pane), click **Swap**.\n",
    "4.  Select **Serverless**.\n",
    "5.  Update.\n",
    "*Result:* The job will now spin up instantly and auto-scale.\n",
    "\n",
    "### Delta Live Tables (DLT)\n",
    "1.  Go to your DLT Pipeline settings.\n",
    "2.  Check the box **Serverless**.\n",
    "3.  Save and Run.\n",
    "*Benefit:* Serverless DLT allows for faster development cycles and incremental refreshes on materialized views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8fba6",
   "metadata": {},
   "source": [
    "## 8. Summary & Key Takeaways\n",
    "\n",
    "*   **Speed:** Serverless eliminates the \"cold start\" problem (waiting 5-10 mins for clusters).\n",
    "*   **Simplicity:** No complex cluster configuration (Node types, Driver sizes).\n",
    "*   **Cost:** Pay-as-you-go. Auto-termination is aggressive to save costs when idle.\n",
    "*   **Architecture:** Compute runs in Databricks' secure account, connecting to your storage.\n",
    "*   **Tracking:** Always use Budget Policies with Tags to monitor Serverless spend.\n",
    "\n",
    "In the next video, we will dive deeper into **Databricks SQL Warehouses**, which are heavily powered by Serverless technology!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
