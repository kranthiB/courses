{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679c502e",
   "metadata": {},
   "source": [
    "# Databricks CLI: Installation & Authentication\n",
    "\n",
    "**Objective:**\n",
    "In this notebook, we will learn about the Databricks Command Line Interface (CLI). The CLI allows you to interact with Databricks services (Workspaces and Accounts) using commands in your terminal. It is essentially a wrapper around the Databricks REST API.\n",
    "\n",
    "**We will cover:**\n",
    "1.  **Installation**: How to install Databricks CLI on Windows/Linux/Mac.\n",
    "2.  **Authentication**:\n",
    "    *   **U2M (User-to-Machine)**: Using browser-based login.\n",
    "    *   **M2M (Machine-to-Machine)**: Using Service Principals (OAuth).\n",
    "3.  **Configuration**: Understanding Profiles and the `.databrickscfg` file.\n",
    "4.  **Hands-on Commands**: Managing Catalogs, Schemas, and Account-level objects.\n",
    "\n",
    "---\n",
    "**Prerequisites:**\n",
    "*   A Databricks Workspace.\n",
    "*   Admin access to the Databricks Account Console (for M2M setup).\n",
    "*   A local terminal (Command Prompt, PowerShell, or Bash)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be011",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "The installation method depends on your operating system.\n",
    "\n",
    "### **Windows**\n",
    "We can use `winget` (Windows Package Manager).\n",
    "Open your **Command Prompt** or **PowerShell** and run:\n",
    "\n",
    "```bash\n",
    "winget search databricks\n",
    "winget install Databricks.DatabricksCLI\n",
    "```\n",
    "\n",
    "### **Linux / macOS**\n",
    "You can use curl or homebrew.\n",
    "\n",
    "#### For macOS using Homebrew\n",
    "brew tap databricks/tap\n",
    "brew install databricks\n",
    "\n",
    "#### For Linux using curl\n",
    "curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh\n",
    "\n",
    "\n",
    "### **Verification**\n",
    "To verify the installation, run the following command in your terminal. It should return the version (e.g., 0.2xx).\n",
    "\n",
    "```bash\n",
    "databricks -v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9978c1",
   "metadata": {},
   "source": [
    "## 2. Authentication: User-to-Machine (U2M)\n",
    "\n",
    "This method is ideal for local development where a human user is interacting with Databricks. It uses your browser to authenticate.\n",
    "\n",
    "### **Step 1: Run the Auth Command**\n",
    "In your terminal, run the following command. Replace `<your-workspace-url>` with your specific URL (e.g., `https://adb-12345.12.azuredatabricks.net`).\n",
    "\n",
    "```bash\n",
    "databricks auth login --host <your-workspace-url>\n",
    "```\n",
    "\n",
    "### **Step 2: Configure Profile Name**\n",
    "\n",
    "The CLI will ask for a Profile Name. This acts as an alias for this connection.\n",
    "\n",
    "    > Input: sk (or any name you prefer).\n",
    "\n",
    "    > Action: A browser window will open. Log in with your Databricks credentials.\n",
    "\n",
    "### **Step 3: Verify Authentication**\n",
    "Once logged in, the terminal will confirm the profile is saved. You can list your profiles:\n",
    "\n",
    "```bash\n",
    "databricks auth profiles\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edff09d",
   "metadata": {},
   "source": [
    "## 3. Configuration: Where are profiles stored?\n",
    "\n",
    "Databricks CLI stores connection profiles in a configuration file located in your user's home directory.\n",
    "\n",
    "*   **File Path:** `~/.databrickscfg` (Linux/Mac) or `%USERPROFILE%\\.databrickscfg` (Windows).\n",
    "*   **Content Structure:** It stores the host URL and token/auth type.\n",
    "\n",
    "To view the content on Windows:\n",
    "```bash\n",
    "notepad %USERPROFILE%\\.databrickscfg\n",
    "```\n",
    "\n",
    "To view on Linux/Mac:\n",
    "```bash\n",
    "cat ~/.databrickscfg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22516304",
   "metadata": {},
   "source": [
    "## 4. Hands-on: Workspace Level Commands\n",
    "\n",
    "Now that we are authenticated, let's run some commands against the workspace.\n",
    "\n",
    "**Note:** Always use the `-p <profile-name>` flag if you have multiple profiles.\n",
    "\n",
    "### **A. List Catalogs**\n",
    "View all catalogs in Unity Catalog.\n",
    "\n",
    "```bash\n",
    "databricks catalogs list -p sk\n",
    "```\n",
    "\n",
    "### **B. Get Help**\n",
    "To understand available commands for a specific service.\n",
    "\n",
    "```bash\n",
    "databricks catalogs --help\n",
    "databricks schemas --help\n",
    "```\n",
    "\n",
    "### **C. Create a Schema**\n",
    "Let's create a new schema named schema_cli inside the dev catalog.\n",
    "\n",
    "**Command Syntax:**\n",
    "\n",
    "databricks schemas create <schema_name> <catalog_name> -p <profile>\n",
    "\n",
    "```bash\n",
    "databricks schemas create schema_cli dev -p sk\n",
    "```\n",
    "\n",
    "**Go to your Databricks UI -> Catalog Explorer to verify the creation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56578b15",
   "metadata": {},
   "source": [
    "## 5. Authentication: Machine-to-Machine (M2M)\n",
    "\n",
    "This method is used for CI/CD pipelines (e.g., Azure DevOps, GitHub Actions) where no human interaction is possible. We use a **Service Principal**.\n",
    "\n",
    "### **Step 1: Create Service Principal & Secret**\n",
    "1.  Go to **Databricks Account Console** -> **User Management** -> **Service Principals**.\n",
    "2.  Select (or create) a Service Principal (e.g., `self-azure-sp`).\n",
    "3.  Go to **Credentials & Secrets** -> **Generate Secret**.\n",
    "4.  **Important:** Copy the **Client ID** and the generated **Client Secret**.\n",
    "\n",
    "### **Step 2: Configure `.databrickscfg` Manually**\n",
    "Open your `.databrickscfg` file and append the following configuration block. This allows the CLI to act as the Service Principal.\n",
    "\n",
    "```ini\n",
    "[sp-workspace]\n",
    "host          = <workspace-url>\n",
    "client_id     = <service-principal-client-id>\n",
    "client_secret = <service-principal-client-secret>\n",
    "\n",
    "[sp-account]\n",
    "host          = https://accounts.azuredatabricks.net\n",
    "account_id    = <databricks-account-id>\n",
    "client_id     = <service-principal-client-id>\n",
    "client_secret = <service-principal-client-secret>\n",
    "```\n",
    "[sp-workspace]: Used for workspace-level commands (Notebooks, Jobs, Tables).\n",
    "\n",
    "[sp-account]: Used for account-level commands (Metastores, User Management).\n",
    "\n",
    "### **Step 3: Test M2M Authentication**\n",
    "List Catalogs using Service Principal:\n",
    "\n",
    "```bash\n",
    "databricks catalogs list -p sp-workspace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ead0f",
   "metadata": {},
   "source": [
    "## 6. Hands-on: Account Level Commands\n",
    "\n",
    "With the Service Principal configured for the account level (`[sp-account]`), we can manage account resources.\n",
    "\n",
    "### **A. List Metastores**\n",
    "See all metastores attached to your account.\n",
    "\n",
    "```bash\n",
    "databricks account metastores list -p sp-account\n",
    "```\n",
    "\n",
    "### **B. List Account Groups**\n",
    "See all user groups defined in the account console.\n",
    "\n",
    "```bash\n",
    "databricks account groups list -p sp-account\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14db0d",
   "metadata": {},
   "source": [
    "## 7. Summary & Next Steps\n",
    "\n",
    "### **Summary**\n",
    "1.  Installed Databricks CLI via `winget`.\n",
    "2.  Authenticated using **U2M** (Browser) for local dev.\n",
    "3.  Authenticated using **M2M** (Service Principal) for automation.\n",
    "4.  Manipulated Unity Catalog objects (Catalogs/Schemas) via CLI.\n",
    "5.  Accessed Account Console data via CLI.\n",
    "\n",
    "### **Next Steps**\n",
    "In the next video, we will explore **Databricks Asset Bundles (DABs)** using the CLI commands (`databricks bundle`) to manage and deploy code as a package."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
