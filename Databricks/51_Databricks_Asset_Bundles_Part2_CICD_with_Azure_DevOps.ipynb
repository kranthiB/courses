{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32a2f9b",
   "metadata": {},
   "source": [
    "# Databricks Asset Bundles (DABs) - Part 2\n",
    "## CI/CD with Azure DevOps\n",
    "\n",
    "In the previous session, we configured a DAB project and deployed it to a **Dev** environment using the CLI and UI.\n",
    "In this session, we will automate the deployment to a **QA (Quality Assurance)** environment using **Azure DevOps Pipelines**.\n",
    "\n",
    "### Learning Objectives\n",
    "1.  Setup permissions for Service Principals in Databricks.\n",
    "2.  Configure **Azure DevOps Variable Groups** for secure credential management.\n",
    "3.  Write an **Azure Pipeline YAML** (`azure-pipelines.yml`) for DAB deployment.\n",
    "4.  Understand how to parameterize pipelines for different environments.\n",
    "5.  Deploy the bundle to a QA workspace using the Service Principal.\n",
    "\n",
    "### Prerequisites\n",
    "*   A **QA Databricks Workspace** (separate from Dev).\n",
    "*   An **Azure Service Principal (SP)** created and added to the Databricks Account.\n",
    "*   **Azure DevOps Project** connected to your Git repository.\n",
    "*   **Parallel Jobs** (Free Tier or Paid) enabled in Azure DevOps to run pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32166ad0",
   "metadata": {},
   "source": [
    "## 1. Security & Permissions Setup\n",
    "\n",
    "Before automating deployment, we need to ensure the Service Principal (SP) has the right access. We do not deploy to QA/Prod using user credentials; we use a Service Principal.\n",
    "\n",
    "### Step 1: Workspace Access\n",
    "1.  Go to **Databricks Account Console** -> **Workspaces** -> Select **QA Workspace**.\n",
    "2.  Go to **Permissions** -> **Add permissions**.\n",
    "3.  Search for your **Service Principal** (e.g., `azure-sp`).\n",
    "4.  Grant **Admin** role (required to create jobs/pipelines/schemas).\n",
    "\n",
    "### Step 2: Catalog Permissions\n",
    "1.  Log in to the **QA Workspace**.\n",
    "2.  Go to **Catalog Explorer**.\n",
    "3.  Select the target catalog (e.g., `qa`).\n",
    "4.  Click **Permissions** -> **Grant**.\n",
    "5.  Grant **ALL PRIVILEGES** to the Service Principal. This allows the SP to create the `bronze` schema defined in our bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b777d",
   "metadata": {},
   "source": [
    "## 2. Azure DevOps Variable Groups\n",
    "\n",
    "To securely pass secrets (Client ID, Client Secret, Host URL) to the pipeline without hardcoding them in the repository, we use **Variable Groups**.\n",
    "\n",
    "1.  Go to **Azure DevOps** -> **Pipelines** -> **Library**.\n",
    "2.  Click **+ Variable group**.\n",
    "3.  Name it: `qa_variables` (Naming convention is important for dynamic referencing).\n",
    "4.  Add the following variables:\n",
    "    *   `DATABRICKS_HOST`: URL of your QA workspace (e.g., `https://adb-xxxx.net`).\n",
    "    *   `CLIENT_ID`: Application (client) ID of your Service Principal.\n",
    "    *   `CLIENT_SECRET`: Client Secret of your Service Principal (Click the ðŸ”’ icon to secure it).\n",
    "5.  **Save** the group.\n",
    "\n",
    "*Note: For Production, create another group named `prod_variables` with Production credentials.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d813c",
   "metadata": {},
   "source": [
    "## 3. Updating `databricks.yml` for QA\n",
    "\n",
    "We need to ensure our bundle configuration knows about the QA environment.\n",
    "\n",
    "Update `databricks.yml`:\n",
    "\n",
    "```yaml\n",
    "targets:\n",
    "  dev:\n",
    "    # ... (dev config)\n",
    "  \n",
    "  qa:\n",
    "    workspace:\n",
    "      host: https://adb-<your-qa-workspace-url>.net\n",
    "    # We don't set 'mode: development' here, so it acts as a production deployment\n",
    "    # It will deploy artifacts to the workspace (not source-linked)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef8c45",
   "metadata": {},
   "source": [
    "## 4. Creating the Azure Pipeline YAML\n",
    "\n",
    "Create a file named `azure-pipelines.yml` in the root of your repository.\n",
    "\n",
    "### Key Components of the Pipeline:\n",
    "1.  **Trigger**: Set to `none` for manual triggering (can be changed to `main` for automated CI).\n",
    "2.  **Parameters**: To allow selecting Environment (`env`) and Catalog (`catalog`) at runtime.\n",
    "3.  **Variables**: Dynamically load the Variable Group based on the selected environment (`${{ parameters.env }}_variables`).\n",
    "4.  **Steps**:\n",
    "    *   Install Databricks CLI.\n",
    "    *   Setup Authentication Profile.\n",
    "    *   Validate, Summarize, and Deploy Bundle.\n",
    "\n",
    "### The Code (`azure-pipelines.yml`)\n",
    "\n",
    "```yaml\n",
    "# Azure Pipeline for DABs Deployment\n",
    "trigger: none\n",
    "\n",
    "pool:\n",
    "  vmImage: ubuntu-latest\n",
    "\n",
    "parameters:\n",
    "  - name: env\n",
    "    displayName: Environment\n",
    "    type: string\n",
    "    default: qa\n",
    "    values:\n",
    "      - dev\n",
    "      - qa\n",
    "  \n",
    "  - name: catalog\n",
    "    displayName: Target Catalog Name\n",
    "    type: string\n",
    "    default: qa\n",
    "\n",
    "variables:\n",
    "  - group: ${{ parameters.env }}_variables\n",
    "\n",
    "stages:\n",
    "  - stage: onRelease\n",
    "    jobs:\n",
    "      - job: ReleaseJob\n",
    "        displayName: Deploy Databricks Asset Bundle\n",
    "        steps:\n",
    "          - checkout: self\n",
    "            displayName: Checkout Source Code\n",
    "\n",
    "          # Step 1: Install Databricks CLI\n",
    "          - script: |\n",
    "              curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh\n",
    "            displayName: 'Install Databricks CLI'\n",
    "\n",
    "          # Step 2: Authenticate (M2M Profile)\n",
    "          # We create a .databrickscfg file with the secrets from Variable Group\n",
    "          - script: |\n",
    "              echo \"[azure-sp]\" >> ~/.databrickscfg\n",
    "              echo \"host = $(DATABRICKS_HOST)\" >> ~/.databrickscfg\n",
    "              echo \"client_id = $(CLIENT_ID)\" >> ~/.databrickscfg\n",
    "              echo \"client_secret = $(CLIENT_SECRET)\" >> ~/.databrickscfg\n",
    "            displayName: 'Setup Authentication Profile'\n",
    "\n",
    "          # Step 3: Validate Profile\n",
    "          - script: |\n",
    "              databricks auth profiles\n",
    "            displayName: 'List Auth Profiles'\n",
    "\n",
    "          # Step 4: Validate Bundle\n",
    "          # We pass the profile 'azure-sp' and override the catalog variable dynamically\n",
    "          - script: |\n",
    "              databricks bundle validate --target ${{ parameters.env }} --profile azure-sp --var \"catalog=${{ parameters.catalog }}\"\n",
    "            displayName: 'Validate Bundle Configuration'\n",
    "\n",
    "          # Step 5: Deploy Bundle\n",
    "          - script: |\n",
    "              databricks bundle deploy --target ${{ parameters.env }} --profile azure-sp --var \"catalog=${{ parameters.catalog }}\"\n",
    "            displayName: 'Deploy Bundle to ${{ parameters.env }}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb99673",
   "metadata": {},
   "source": [
    "## 5. Executing the Deployment\n",
    "\n",
    "1.  **Push Code**: Commit and push the `azure-pipelines.yml` and updated `databricks.yml` to your repository.\n",
    "2.  **Create Pipeline**:\n",
    "    *   In Azure DevOps, go to **Pipelines** -> **New Pipeline**.\n",
    "    *   Select **Azure Repos Git** -> Your Repository.\n",
    "    *   Select **Existing Azure Pipelines YAML file** and point to `azure-pipelines.yml`.\n",
    "3.  **Run Pipeline**:\n",
    "    *   Click **Run Pipeline**.\n",
    "    *   Select `qa` for Environment and type `qa` for Catalog.\n",
    "    *   **Approve Permission**: The first time you run, you will be asked to permit access to the `qa_variables` group. Click **Permit**.\n",
    "\n",
    "### What happens during deployment?\n",
    "Unlike the Dev deployment (Source-Linked), deploying to QA via this pipeline does the following:\n",
    "1.  Uploads all source files (notebooks, YAMLs) to a hidden location in the QA Workspace (`/Users/<sp-id>/.bundle/...`).\n",
    "2.  Creates/Updates the Jobs and Pipelines in QA to point to these uploaded files.\n",
    "3.  Creates the Schema defined in the resources (if it doesn't exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd198a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Validation Script (Local)\n",
    "# Before pushing to Azure DevOps, you can validate your changes locally using the CLI.\n",
    "# Note: You need the profile configured locally or use your user credentials.\n",
    "\n",
    "# !databricks bundle validate -t dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21940030",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "We have successfully built a complete CI/CD workflow for Databricks:\n",
    "\n",
    "| Environment | Deployment Method | Credential | Artifact Location |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Dev** | CLI / UI (Manual) | User (You) | Workspace Repo (Source-Linked) |\n",
    "| **QA** | Azure Pipeline (Automated) | Service Principal | `.bundle` Folder (Isolated Copy) |\n",
    "\n",
    "This ensures that developers can iterate fast in Dev without affecting others, while QA/Prod deployments are stable, isolated, and managed via version control and automation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
