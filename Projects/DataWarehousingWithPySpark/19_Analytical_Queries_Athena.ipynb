{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8981e0",
   "metadata": {},
   "source": [
    "# Analytics & Reporting on AWS Athena\n",
    "\n",
    "## Overview\n",
    "We have successfully built an End-to-End Data Lakehouse using PySpark and Delta Lake.\n",
    "*   **Landing:** Raw Data Ingestion.\n",
    "*   **Staging:** Cleaning, Deduplication, Transformation.\n",
    "*   **Data Warehouse:** Star Schema (Facts & Dimensions) with SCD1/SCD2 logic.\n",
    "\n",
    "Now, we act as Data Analysts. We will use **AWS Athena** (a serverless query engine) to run SQL queries on top of our Delta Lake tables to generate business insights.\n",
    "\n",
    "## Prerequisites\n",
    "*   AWS Credentials configured.\n",
    "*   Athena tables created (via Symlink Manifest in previous steps).\n",
    "*   `boto3` library installed.\n",
    "\n",
    "## Reports to Generate\n",
    "1.  **Total Sales per Store:** Evaluate store performance.\n",
    "2.  **Top Selling Products:** Identify high-demand items.\n",
    "3.  **Sales by Plan Type:** Understand customer segmentation revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488a8ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "aws_region = \"ap-south-1\" # Update to your region\n",
    "athena_output_loc = \"s3://warehouse/target/athena_output/\"\n",
    "database = \"edw\" # The Data Warehouse DB created in Athena\n",
    "\n",
    "# Initialize Client\n",
    "athena_client = boto3.client('athena', region_name=aws_region)\n",
    "s3_client = boto3.client('s3', region_name=aws_region)\n",
    "\n",
    "print(f\"Connected to Athena in region: {aws_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11d6fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to run Athena query and return Pandas DataFrame\n",
    "def run_query(query, database, output_location):\n",
    "    try:\n",
    "        # Start Query\n",
    "        response = athena_client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            QueryExecutionContext={'Database': database},\n",
    "            ResultConfiguration={'OutputLocation': output_location}\n",
    "        )\n",
    "        query_id = response['QueryExecutionId']\n",
    "        \n",
    "        # Wait for completion\n",
    "        while True:\n",
    "            stats = athena_client.get_query_execution(QueryExecutionId=query_id)\n",
    "            status = stats['QueryExecution']['Status']['State']\n",
    "            if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "            \n",
    "        if status == 'SUCCEEDED':\n",
    "            # Get Results Key\n",
    "            path = output_location.replace(\"s3://\", \"\")\n",
    "            bucket = path.split(\"/\")[0]\n",
    "            key = path.replace(bucket + \"/\", \"\") + query_id + \".csv\"\n",
    "            \n",
    "            # Read CSV from S3 directly into Pandas\n",
    "            obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "            df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Query Failed: {stats['QueryExecution']['Status']['StateChangeReason']}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ccce22",
   "metadata": {},
   "source": [
    "## Report 1: Total Sales per Store\n",
    "We join `fact_sales` with `dim_store` to aggregate total sales revenue by store name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49eba8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query_1 = \"\"\"\n",
    "SELECT \n",
    "    s.store_name, \n",
    "    SUM(f.line_total) as total_sales\n",
    "FROM fact_sales f\n",
    "JOIN dim_store s ON f.store_wid = s.row_wid\n",
    "GROUP BY s.store_name\n",
    "ORDER BY total_sales DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing Report 1: Total Sales per Store...\")\n",
    "df_sales_store = run_query(query_1, database, athena_output_loc)\n",
    "\n",
    "if df_sales_store is not None:\n",
    "    print(df_sales_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1374bc1b",
   "metadata": {},
   "source": [
    "## Report 2: Top Selling Products\n",
    "We identify which products generate the most revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905829ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query_2 = \"\"\"\n",
    "SELECT \n",
    "    p.product_name, \n",
    "    SUM(f.line_total) as total_sales\n",
    "FROM fact_sales f\n",
    "JOIN dim_product p ON f.product_wid = p.row_wid\n",
    "GROUP BY p.product_name\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing Report 2: Top Selling Products...\")\n",
    "df_top_products = run_query(query_2, database, athena_output_loc)\n",
    "\n",
    "if df_top_products is not None:\n",
    "    print(df_top_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06852ad4",
   "metadata": {},
   "source": [
    "## Report 3: Sales by Plan Type\n",
    "We analyze sales distribution based on Customer Plan Types (Gold, Silver, etc.).\n",
    "*   **Join Path:** `fact_sales` -> `dim_customer` -> `dim_plan_type` (if it exists, or direct attribute if denormalized).\n",
    "*   *Note: Based on the video, Plan Type might be an attribute in Customer or a separate lookup.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d068dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming Plan Type is an attribute in dim_customer for this query\n",
    "query_3 = \"\"\"\n",
    "SELECT \n",
    "    c.plan_type, \n",
    "    SUM(f.line_total) as total_sales\n",
    "FROM fact_sales f\n",
    "JOIN dim_customer c ON f.customer_wid = c.row_wid\n",
    "WHERE c.active_flg = 'Y' -- Only consider current customer attributes\n",
    "GROUP BY c.plan_type\n",
    "ORDER BY total_sales DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing Report 3: Sales by Customer Plan Type...\")\n",
    "df_plan_sales = run_query(query_3, database, athena_output_loc)\n",
    "\n",
    "if df_plan_sales is not None:\n",
    "    print(df_plan_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394771c9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have successfully:\n",
    "1.  Ingested raw data from CSV/JSON into a Data Lake.\n",
    "2.  Processed and modeled data using PySpark and Delta Lake.\n",
    "3.  Served the data via AWS Athena for Analytics.\n",
    "\n",
    "This completes the **Data Warehousing with PySpark** course."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
