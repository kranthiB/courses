{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfb91c3",
   "metadata": {},
   "source": [
    "# PySpark: Zero to Hero\n",
    "## Module 9: Working with Strings, Dates, and Nulls\n",
    "\n",
    "In real-world data engineering, data is rarely clean. You will often encounter:\n",
    "1.  Inconsistent String formatting.\n",
    "2.  Dates stored as Strings.\n",
    "3.  Missing (Null) values.\n",
    "\n",
    "In this notebook, we will learn how to clean and standardize this data.\n",
    "\n",
    "### Agenda:\n",
    "1.  **Conditional Logic:** `when().otherwise()` (Case When).\n",
    "2.  **String Operations:** `regexp_replace`.\n",
    "3.  **Date Operations:** `to_date`, `current_date`, `date_format`.\n",
    "4.  **Null Handling:** `na.drop`, `fill`, and `coalesce`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47874dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, when, expr, regexp_replace, to_date, current_date, current_timestamp, date_format, coalesce\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Strings_Dates_Nulls\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define Employee Data (Notice the Hire Date is a String)\n",
    "# Also introducing a record with Unknown Gender for Null testing\n",
    "data = [\n",
    "    (\"001\", \"John Doe\", \"Male\", \"50000\", \"2015-01-01\"),\n",
    "    (\"002\", \"Jane Smith\", \"Female\", \"45000\", \"2016-04-15\"),\n",
    "    (\"003\", \"Bob Brown\", \"Male\", \"55000\", \"2014-05-01\"),\n",
    "    (\"004\", \"Alice Lee\", \"Female\", \"48000\", \"2017-09-30\"),\n",
    "    (\"005\", \"Jack Chan\", \"Male\", \"60000\", \"2013-04-01\"),\n",
    "    (\"018\", \"N/A\", None, \"1000\", \"2022-01-01\") # Data with Null Gender\n",
    "]\n",
    "\n",
    "columns = [\"emp_id\", \"name\", \"gender\", \"salary\", \"hire_date\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"--- Original Data ---\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d954e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario: We want to standardize Gender.\n",
    "# Male -> M\n",
    "# Female -> F\n",
    "# Null/Other -> null\n",
    "\n",
    "# We use the 'when().otherwise()' function chain.\n",
    "df_gender = df.withColumn(\"short_gender\", \n",
    "    when(col(\"gender\") == \"Male\", \"M\")\n",
    "    .when(col(\"gender\") == \"Female\", \"F\")\n",
    "    .otherwise(None) # Sets value to Null if no condition matches\n",
    ")\n",
    "\n",
    "print(\"--- Gender Standardized (Case When) ---\")\n",
    "df_gender.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b7ff1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario: Replace 'J' with 'Z' in names (e.g., 'John' -> 'Zohn')\n",
    "# We use regexp_replace(column, pattern, replacement)\n",
    "\n",
    "df_regex = df_gender.withColumn(\"cleaned_name\", \n",
    "    regexp_replace(col(\"name\"), \"J\", \"Z\")\n",
    ")\n",
    "\n",
    "print(\"--- Regex Replace Applied ---\")\n",
    "df_regex.select(\"name\", \"cleaned_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509ffa9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario: 'hire_date' is currently a String. We cannot perform date calculations on it.\n",
    "# 1. Convert String to DateType\n",
    "# 2. Add Current Date\n",
    "# 3. Add Current Timestamp\n",
    "\n",
    "df_dates = df_regex \\\n",
    "    .withColumn(\"hire_date_dt\", to_date(col(\"hire_date\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"current_dt\", current_date()) \\\n",
    "    .withColumn(\"current_ts\", current_timestamp())\n",
    "\n",
    "print(\"--- Date Transformations ---\")\n",
    "df_dates.printSchema() # Notice hire_date_dt is now 'date' type\n",
    "df_dates.select(\"hire_date\", \"hire_date_dt\", \"current_dt\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c00439",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Scenario: We want to extract just the Year from the hire date.\n",
    "# We use date_format() with the \"y\" pattern.\n",
    "\n",
    "df_year = df_dates.withColumn(\"hire_year\", date_format(col(\"hire_date_dt\"), \"yyyy\"))\n",
    "\n",
    "print(\"--- Extracted Year ---\")\n",
    "df_year.select(\"hire_date_dt\", \"hire_year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c776588",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Handling Nulls in a Column (Filling default value)\n",
    "# Scenario: If 'short_gender' is Null, fill it with 'O' (Other).\n",
    "# We use coalesce() which returns the first non-null value.\n",
    "\n",
    "df_filled = df_year.withColumn(\"short_gender_fixed\", \n",
    "    coalesce(col(\"short_gender\"), lit(\"O\"))\n",
    ")\n",
    "\n",
    "print(\"--- Nulls Filled with 'O' ---\")\n",
    "df_filled.select(\"name\", \"gender\", \"short_gender\", \"short_gender_fixed\").show()\n",
    "\n",
    "\n",
    "# 2. Dropping Rows with Nulls\n",
    "# Scenario: If a critical column (like name) is 'N/A' or Null, we drop the row.\n",
    "# Note: na.drop() drops rows containing ANY nulls by default.\n",
    "\n",
    "df_dropped = df_filled.na.drop()\n",
    "\n",
    "print(\"--- Rows with Nulls Dropped ---\")\n",
    "df_dropped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad61ee1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1.  **`when(condition, value).otherwise(value)`**: The standard way to implement IF/ELSE logic.\n",
    "2.  **`regexp_replace`**: Powerful string manipulation using Regex patterns.\n",
    "3.  **`to_date(col, format)`**: Essential for converting strings to dates for calculation.\n",
    "4.  **`date_format(col, pattern)`**: Extracts specific parts of a date (Year, Month, etc.).\n",
    "5.  **`coalesce(col1, col2)`**: Returns the first non-null value (Great for filling defaults).\n",
    "6.  **`na.drop()`**: Removes rows with missing data.\n",
    "\n",
    "**Next Steps:**\n",
    "In the next module, we will dive into **Aggregations**: `GroupBy`, `Count`, `Sum`, `Avg`, and sorting data using `OrderBy`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
