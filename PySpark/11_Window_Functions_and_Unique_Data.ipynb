{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee458e52",
   "metadata": {},
   "source": [
    "# PySpark: Zero to Hero\n",
    "## Module 11: Window Functions & Unique Data\n",
    "\n",
    "In this module, we tackle advanced analytical problems.\n",
    "1.  **Distinct Data:** Removing duplicates.\n",
    "2.  **Window Functions:** The superpower of SQL/Spark for ranking and running totals.\n",
    "3.  **Bonus:** Introduction to Databricks Community Cloud.\n",
    "\n",
    "### Scenario:\n",
    "We want to find the **2nd Highest Salary** in each department. This is impossible with standard `groupBy` but easy with Window Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4f422",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, row_number, rank, dense_rank, desc\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Window_Functions_Demo\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create Employee Data with duplicates and varying salaries\n",
    "data = [\n",
    "    (\"001\", \"John Doe\", \"IT\", 70000),\n",
    "    (\"002\", \"Jane Smith\", \"IT\", 65000),\n",
    "    (\"003\", \"Bob Brown\", \"IT\", 80000),\n",
    "    (\"004\", \"Alice Lee\", \"HR\", 50000),\n",
    "    (\"005\", \"Jack Chan\", \"HR\", 50000), # Duplicate Salary in HR\n",
    "    (\"006\", \"Jill Wong\", \"HR\", 60000),\n",
    "    (\"001\", \"John Doe\", \"IT\", 70000)  # Duplicate Row\n",
    "]\n",
    "columns = [\"emp_id\", \"name\", \"dept\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"--- Original Data (With Duplicates) ---\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec4979",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Get Distinct Rows (Removes fully duplicate rows)\n",
    "df_unique = df.distinct()\n",
    "\n",
    "print(\"--- Unique Rows ---\")\n",
    "df_unique.show()\n",
    "\n",
    "# 2. Drop Duplicates based on specific columns\n",
    "# E.g., If emp_id is same, keep only one (regardless of other columns)\n",
    "df_deduped = df.dropDuplicates([\"emp_id\"])\n",
    "\n",
    "print(\"--- Deduped by Employee ID ---\")\n",
    "df_deduped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731abce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Problem: Find the 2nd Highest Salary per Department.\n",
    "\n",
    "# Step 1: Define the Window Specification\n",
    "# Partition by Department -> Sort by Salary Descending\n",
    "window_spec = Window.partitionBy(\"dept\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "# Step 2: Apply Window Function (Row Number)\n",
    "# row_number() gives a sequential number 1, 2, 3... within the window partition\n",
    "df_ranked = df_unique.withColumn(\"rank\", row_number().over(window_spec))\n",
    "\n",
    "print(\"--- Ranked Data (Row Number) ---\")\n",
    "df_ranked.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0e6d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Now that we have the rank, filtering is easy.\n",
    "# Get the 2nd highest salary (Rank = 2)\n",
    "\n",
    "df_second_highest = df_ranked.filter(col(\"rank\") == 2)\n",
    "\n",
    "print(\"--- 2nd Highest Salary per Department ---\")\n",
    "df_second_highest.drop(\"rank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e30ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# What if salaries are tied? (See HR department: 50,000 appears twice)\n",
    "\n",
    "# 1. Rank: Skips numbers (1, 2, 2, 4)\n",
    "# 2. Dense Rank: No skipping (1, 2, 2, 3)\n",
    "\n",
    "window_spec = Window.partitionBy(\"dept\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "df_comparison = df_unique \\\n",
    "    .withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "    .withColumn(\"rank\", rank().over(window_spec)) \\\n",
    "    .withColumn(\"dense_rank\", dense_rank().over(window_spec))\n",
    "\n",
    "print(\"--- Row Number vs Rank vs Dense Rank ---\")\n",
    "df_comparison.filter(col(\"dept\") == \"HR\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeadf8b",
   "metadata": {},
   "source": [
    "## Bonus Tip: Databricks Community Cloud\n",
    "\n",
    "If you cannot install Docker locally, you can use **Databricks Community Edition** for free.\n",
    "\n",
    "1.  **URL:** [community.cloud.databricks.com](https://community.cloud.databricks.com)\n",
    "2.  **Sign Up:** Choose the \"Community Edition\" (Free, no credit card required).\n",
    "3.  **Cluster:** It gives you a micro-cluster (15GB RAM) that terminates after 2 hours of inactivity.\n",
    "4.  **Usage:** The code we write here works **exactly 100% same** in Databricks notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f1b050",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1.  **`distinct()`**: Removes fully duplicate rows.\n",
    "2.  **`dropDuplicates([cols])`**: Removes duplicates based on specific columns.\n",
    "3.  **Window Functions:**\n",
    "    *   Require `Window.partitionBy(...).orderBy(...)`.\n",
    "    *   **`row_number()`**: Unique sequential number (1, 2, 3, 4).\n",
    "    *   **`rank()`**: Skips on ties (1, 2, 2, 4).\n",
    "    *   **`dense_rank()`**: No skipping on ties (1, 2, 2, 3).\n",
    "\n",
    "**Next Steps:**\n",
    "We are now ready to handle complex Data Engineering tasks. In the next module, we will tackle **Data Repartitioning & Coalesce**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
