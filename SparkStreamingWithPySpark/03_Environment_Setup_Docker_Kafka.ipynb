{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e34ac547",
   "metadata": {},
   "source": [
    "# Spark Streaming with PySpark\n",
    "## Module 3: Environment Setup (Docker, Spark & Kafka)\n",
    "\n",
    "In this module, we will set up the complete infrastructure required for this course. Unlike standard batch processing, Streaming requires a **Message Broker**. We will use **Apache Kafka**.\n",
    "\n",
    "To make the setup easy and consistent across Windows, Mac, and Linux, we will use **Docker**.\n",
    "\n",
    "### The Architecture\n",
    "We are building a multi-container environment:\n",
    "1.  **Jupyter Lab (PySpark):** Where we write our code.\n",
    "2.  **Apache Kafka:** The streaming message broker.\n",
    "3.  **Zookeeper:** Manages the Kafka cluster.\n",
    "\n",
    "### Prerequisites\n",
    "1.  **Docker Desktop:** Download and install from [docker.com](https://www.docker.com/products/docker-desktop/).\n",
    "2.  **Git:** (Optional) to clone the repository, or you can download the ZIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70246a",
   "metadata": {},
   "source": [
    "## Step 1: Get the Docker Compose File\n",
    "We need the configuration files to tell Docker how to build our cluster.\n",
    "\n",
    "1.  Go to the GitHub Repository: [https://github.com/subhamkharwal/docker-images](https://github.com/subhamkharwal/docker-images)\n",
    "2.  **Clone** or **Download ZIP** of the repository.\n",
    "3.  Navigate to the folder:\n",
    "    > `docker-images/pyspark-jupyter-kafka`\n",
    "\n",
    "## Step 2: Start the Cluster\n",
    "1.  Open your **Terminal** or **Command Prompt**.\n",
    "2.  Change directory (`cd`) into the folder you just downloaded (`pyspark-jupyter-kafka`).\n",
    "3.  Run the build command:\n",
    "    ```bash\n",
    "    docker-compose up\n",
    "    ```\n",
    "4.  Wait for the logs to stop scrolling. You should see messages indicating Kafka and Jupyter are running.\n",
    "\n",
    "## Step 3: Access Jupyter Lab\n",
    "1.  Open your browser to [http://localhost:8888](http://localhost:8888).\n",
    "2.  **Token:** Check the terminal logs for a URL like `http://127.0.0.1:8888/lab?token=...`. Copy the token string.\n",
    "3.  **Login:** Paste the token and set a password (e.g., `1234`) for future easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468036ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Environment_Check\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created Successfully!\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "\n",
    "# 2. Check UI\n",
    "print(\"You can view the Spark UI at: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9bb3e7",
   "metadata": {},
   "source": [
    "## Verification 2: Kafka Connection\n",
    "\n",
    "To ensure Kafka is working, we will perform a manual check using the terminal inside the Kafka container.\n",
    "\n",
    "**Steps:**\n",
    "1.  Open **Docker Desktop**.\n",
    "2.  Find the container named **`ed-kafka`**.\n",
    "3.  Click on the **\"Exec\"** or **\"Terminal\"** tab (or the CLI icon).\n",
    "4.  Run the following commands inside that terminal:\n",
    "\n",
    "**A. Create a Test Topic:**\n",
    "```bash\n",
    "kafka-topics --create --topic test-topic --bootstrap-server ed-kafka:9092\n",
    "\n",
    "# Expected Output: Created topic test-topic.\n",
    "\n",
    "kafka-topics --list --bootstrap-server ed-kafka:9092\n",
    "\n",
    "# Expected Output: You should see test-topic listed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17ba1b",
   "metadata": {},
   "source": [
    "### **Useful Commands**\n",
    "\n",
    "```markdown\n",
    "## Cheat Sheet: Docker Commands\n",
    "\n",
    "Save these commands for reference throughout the course.\n",
    "\n",
    "| Action | Command (Run in local terminal) |\n",
    "| :--- | :--- |\n",
    "| **Start Cluster** | `docker-compose up` |\n",
    "| **Stop Cluster** | Press `Ctrl + C` or run `docker-compose down` |\n",
    "| **Check Containers** | `docker ps` |\n",
    "\n",
    "### Spark UI Ports\n",
    "*   **Jupyter Lab:** [localhost:8888](http://localhost:8888)\n",
    "*   **Spark UI:** [localhost:4040](http://localhost:4040) (Active only when a SparkSession is running)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
