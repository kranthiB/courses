{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975ee894",
   "metadata": {},
   "source": [
    "# Spark Streaming with PySpark\n",
    "## Module 16: Window Operations\n",
    "\n",
    "Aggregating data over time is a fundamental requirement in streaming. For example: *\"Count the number of errors every 5 minutes\"* or *\"Calculate the average temperature over the last hour, updating every 10 minutes.\"*\n",
    "\n",
    "Spark Structured Streaming provides three types of time windows to handle these scenarios.\n",
    "\n",
    "### Objectives:\n",
    "1.  **Tumbling Windows (Fixed):** Non-overlapping, contiguous time intervals.\n",
    "2.  **Sliding Windows (Overlapping):** Fixed duration, but moving at a specific interval.\n",
    "3.  **Session Windows (Dynamic):** Based on user activity, not fixed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a550bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, window, avg, count\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Window_Operations_Demo\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed9516",
   "metadata": {},
   "source": [
    "## 1. Tumbling Windows (Fixed)\n",
    "\n",
    "*   **Description:** A series of fixed-sized, non-overlapping and contiguous time intervals.\n",
    "*   **Behavior:** An input can belong to **only one** window.\n",
    "*   **Example:** \"Count events every 10 minutes.\"\n",
    "    *   Window 1: 12:00 - 12:10\n",
    "    *   Window 2: 12:10 - 12:20\n",
    "\n",
    "**Syntax:**\n",
    "`window(timeColumn, windowDuration)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd15b6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example Logic (Not running stream, just defining query)\n",
    "\n",
    "# Assume df has column 'eventTime' and 'temperature'\n",
    "# Calculate average temperature every 10 minutes\n",
    "# Tumbling Window: size=\"10 minutes\"\n",
    "\n",
    "# tumbling_df = raw_df.groupBy(\n",
    "#     window(col(\"eventTime\"), \"10 minutes\"),\n",
    "#     col(\"deviceId\")\n",
    "# ).agg(avg(\"temperature\").alias(\"avg_temp\"))\n",
    "\n",
    "print(\"Tumbling Window logic defined (Code is commented to prevent execution without data source).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83ba3f",
   "metadata": {},
   "source": [
    "## 2. Sliding Windows (Overlapping)\n",
    "\n",
    "*   **Description:** Fixed-sized windows that \"slide\" over time.\n",
    "*   **Behavior:** An input can belong to **multiple** windows if the slide duration is smaller than the window duration.\n",
    "*   **Example:** \"Calculate average temperature over the **last 10 minutes**, updating **every 5 minutes**.\"\n",
    "    *   Window 1: 12:00 - 12:10\n",
    "    *   Window 2: 12:05 - 12:15 (Overlaps with Window 1 by 5 mins)\n",
    "\n",
    "**Syntax:**\n",
    "`window(timeColumn, windowDuration, slideDuration)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf582fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example Logic\n",
    "# Window Size: 10 minutes\n",
    "# Slide Duration: 5 minutes\n",
    "\n",
    "# sliding_df = raw_df.groupBy(\n",
    "#     window(col(\"eventTime\"), \"10 minutes\", \"5 minutes\"),\n",
    "#     col(\"deviceId\")\n",
    "# ).agg(avg(\"temperature\").alias(\"avg_temp\"))\n",
    "\n",
    "print(\"Sliding Window logic defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c53cbb",
   "metadata": {},
   "source": [
    "## 3. Session Windows (Dynamic)\n",
    "\n",
    "*   **Description:** Windows that do not have a fixed start or end time. They are defined by periods of activity followed by a gap of inactivity.\n",
    "*   **Behavior:** Useful for user sessions (e.g., web analytics). A session closes when no data arrives for a specific \"gap\" duration.\n",
    "*   **Example:** \"Group user clicks into sessions. If the user is idle for 30 minutes, close the session.\"\n",
    "\n",
    "**Syntax:**\n",
    "`session_window(timeColumn, gapDuration)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d6eab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import session_window\n",
    "\n",
    "# Example Logic\n",
    "# Gap Duration: 30 minutes (Session closes after 30 mins of inactivity)\n",
    "\n",
    "# session_df = raw_df.groupBy(\n",
    "#     session_window(col(\"eventTime\"), \"30 minutes\"),\n",
    "#     col(\"userId\")\n",
    "# ).count()\n",
    "\n",
    "print(\"Session Window logic defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5270cf7",
   "metadata": {},
   "source": [
    "## Up Next: Implementation\n",
    "\n",
    "In the next module, we will take our **Device Data** pipeline and implement these windows practically. We will see how **Late Data** affects these windows and how to handle it using **Watermarking**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
